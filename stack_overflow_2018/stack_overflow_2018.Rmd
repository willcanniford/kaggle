---
title: "Stack Overflow 2018 Developer Survey: Insights & Visualisations"
author: "Will Canniford"
output: 
  html_document:
    number_sections: false
    toc: true
    toc_depth: 6
    highlight: tango
    theme: yeti
    code_folding: show
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

*** 

# Introduction
We have the data for the Stack Overflow 2018 Developer Survey, with each row corresponding to one respondent to the survey and the columns representing the questions that were asked: `survey_results_public.csv`.  
We are also provided with another file that is the schema for the survey: `survey_results_schema.csv`. This provides us with the full questions that were asked. 

***

# Loading in the data
## Packages
Let's start by loading the packages that we are going to use throughout the analysis. I will also set the theme for my graphics so that I don't have to include the code each time.   
```{r "load_packages", message=FALSE, error=FALSE}
library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
```  

## The files
I will read in both files using `read_csv` from the `readr` package. I will keep the column specification parsing default to allow for automatic typing. 
```{r "load_files", message=FALSE, error=FALSE}
schema <- read_csv('./input/survey_results_schema.csv')
replies <- read_csv('./input/survey_results_public.csv')
```
  
  
## Initial structure exploration
Now that we have read the files in, we can begin to explore them to find out more about the structure of the data that we are going to be working with. 

```{r "check_replies_dimensions"}
dim(replies) # Get the dimensions of the replies data
```
It looks as though we have almost 100,000 respondents to the survey and comfortably over 100 questions in the survey.  

```{r}
head(replies, n = 1) # View first row
```
This shows us that we have a respondent id column currently named `Respondent`. This also shows us that all the column titles appear to be in ___CamelCase___ of sorts.  
Given the way the single row has displayed indicates that some of the answers are quite long and are wrapping badly to make displaying the data quite space-filling.  

*So does that mean that there are 128 questions?*
```{r "schema_dimensions"}
dim(schema) # Dimensions of the schema 
```
129 rows definitely aligns with the 129 columns that we have in the `replies` data. 

```{r "show_head_schema"}
head(schema, n = 5)
```
The first row is an explanation of the id column that we had already spotted, so I'm going to assume that there were 128 questions in the survey, or at least 128 opportunities to collect information from the respondent.   

## Missing values 
Let's have a quick look at the missing values in the data using the `map` functions from the `purrr` package. 

```{r "map_missing_values"}
map_df(replies, ~ sum(is.na(.))) %>%
  gather("question", "n_missing") %>%
  mutate(perc_answered = (nrow(replies) - n_missing) / nrow(replies) * 100)
```  
It looks as though the survey was mainly made of optional questions. As we would expect the `Respondent` column has a 100% complete rate, as do the `Hobby` and `OpenSource` questions.  

The other things that jump out are the longer questions such as `AssessJob` and `AssessBenefits`. These have exactly the same number of missing values from the respondents, making us think that they represent effectively one larger question, rather than a group of questions. 

***

# Insights 
## Hobbyists and contributors 
There are two questions in particular that deal with these titles: `Hobby` and `OpenSource`. If we have a look at the scheme then we are able to see exactly what the questions were:

```{r 'hobby_open_source_questions'}
schema %>% filter(Column %in% c('Hobby', 'OpenSource'))
```

We can use these to show how many of the respondents are coding as a hobby and contributing to open source projects.  

```{r}
replies %>%
    filter(!is.na(Hobby)) %>%
    ggplot(aes(Hobby, fill = Hobby)) + 
        geom_bar() + 
        labs(x = 'Do you code as a hobby?', y = 'Count') +
        guides(fill = FALSE)
```  

It looks as though we have a large proportion of hobbyists in the data! What about contributors to open source?

```{r}
replies %>%
    filter(!is.na(OpenSource)) %>%
    ggplot(aes(OpenSource, fill = OpenSource)) + 
        geom_bar() + 
        labs(x = 'Do you contribute to open source projects?', y = 'Count') +
        guides(fill = FALSE)
```  

There seem to be much fewer people that contribute to open source projects. Assumingly, when they are coding at home they are working on small personal projects instead. 

***

## Represented countries 
*What are the most represented countries among our respondents?*  
We can have a look using the `Country` column from the `replies` data. I will plot the 10 countries that the respondents listed as their country. 
```{r "top_10_countries", message=FALSE}
top_10_countries <- replies %>%
  group_by(Country) %>%
  summarise(n_respondents = n()) %>%
  arrange(desc(n_respondents)) %>%
  top_n(10)

ggplot(top_10_countries, aes(reorder(Country, n_respondents), n_respondents)) + 
  geom_col() + 
  coord_flip() + 
  labs(x = 'Country', y = 'Number of respondents', title = 'Respondent count by country')
```  

We see that the United States leads the way with most reponses, followed by India, Germany and the United Kingdom.  

*How many countries are represented in these survey respondents?*  

```{r}
replies %>% 
  filter(!is.na(Country)) %>% 
  summarise(unique = n_distinct(Country)) %>% 
  '$'(unique)
```  
183 countries are represented!  

***

## Current developer roles 
We can find out what type of roles the respondents are currently in by looking at the `DevType` variable. Let's have a look at the question by querying `schema`.  

```{r 'dev_type_question'}
schema %>% filter(Column == 'DevType') %>% '$'(QuestionText)
```

It looks like we are going to be working with a multiple choice answer, so we should look at some examples to see what form the answer is stored in.  

```{r 'dev_type_example'}
replies %>% select(DevType) %>% head()
```

It seems to be stored as a string with a separator of '**;**'. We can use the `stringr` package to help us manage these answers and see what the most common dev type describes our respondents.  

```{r}
all_dev_types <- unlist(str_split(replies$DevType, ';'))
head(all_dev_types)
```

Now that we have split the developer types from the column, we can plot to see which was the most common developer type.  

```{r}
as_tibble(table(all_dev_types)) %>%
    ggplot(aes(reorder(all_dev_types, n), n, fill = all_dev_types)) + 
        geom_col() +
        coord_flip() + 
        labs(x = 'Developer Role', y = 'Count', title = 'Most common developer roles') + 
        guides(fill = FALSE) # Remove legend
```  

Back-end, Full-stack and Front-end developers lead the way with the roles that are used to describe what the respondents are doing. 

***

## Age of respondents
Let's move on and have a look at the `Age` of the respondents that we have.  

```{r "age_structure"}
class(replies$Age) # Let's see what type of variable Age is
```
We can see that age isn't stored as a numeric variable, which would have been my first thought but it is stored as a character. Let's see the type of responses that were given. 

```{r}
unique(replies$Age)
```

We are looking at categorical predefined bins that they provided, probably as a select box for the respondents.

```{r "age_plotting"}
ggplot(replies, aes(Age, fill = factor(Age))) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(y = 'Number of respondents', title = 'Age of respondents') + 
  guides(fill = FALSE)
```
  
We can see that the most common age group of respondents is actually `NA`. Perhaps developers just aren't keen to give away how old they are.  
The respondents are generally dominated with those developers under the age of 35.  

***

## Coding experience 
Also included in the survey is information about what stage in their career the respondents are, and what sort of experience they have with programming.  

Just a few of the variables that relate to this area are: `YearsCoding`, `YearsCodingProf`, `UndergradMajor` and `Employment`

Let's have a look at the variables that related to the number of years that the respondent has been coding (`YearsCoding` and `YearsCodingProf`).  

```{r 'initial_coding_summaries' }
summary(replies$YearsCoding)
summary(replies$YearsCodingProf)
```  

So they are both character classes, so this probably means that this was a select box in the survey rather than a numeric input.  

```{r 'initial_coding_prof_summaries' }
unique(replies$YearsCoding)
unique(replies$YearsCodingProf)
```  

So it looks as though both the variables have the same binned categories.  

```{r}
replies %>%
  filter(!is.na(YearsCoding)) %>% # Remove blank respondents
  group_by(YearsCoding) %>% # Group by category
  summarise(count = n()) %>%
  ggplot(aes(reorder(YearsCoding, desc(count)), count, fill = factor(YearsCoding))) + 
  geom_col() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  guides(fill = FALSE) + 
  labs(x = 'Years coding', y = 'Count')
```  

It shows us that the majority of the respondents have been coding for more than 3 years, but how long have they been professionally coding? 

```{r}
replies %>%
  filter(!is.na(YearsCodingProf)) %>% # Remove blank respondents
  group_by(YearsCodingProf) %>% # Group by category
  summarise(count = n()) %>%
  ggplot(aes(reorder(YearsCodingProf, desc(count)), count, fill = factor(YearsCodingProf))) + 
  geom_col() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  guides(fill = FALSE) + 
  labs(x = 'Years coding', y = 'Count')
```  
So they have been professional for around 0-2 years in the majority. I suppose that makes sense, that those who have been coding for slightly longer then get their first professional coding job once they have some experience under their belt. However, we aren't comparing the two variables against one another... 

```{r}
# Define levels for each variable
YearsLevels = c("0-2 years", "3-5 years","6-8 years", "9-11 years", "12-14 years", "15-17 years", "18-20 years", "21-23 years", "24-26 years", "27-29 years", "30 or more years") 

# Define order to factor variables
replies$YearsCoding <- factor(replies$YearsCoding, levels = YearsLevels, ordered = TRUE) 
replies$YearsCodingProf <- factor(replies$YearsCodingProf, levels = YearsLevels, ordered = TRUE) 

replies %>%
  select(YearsCoding, YearsCodingProf) %>%
  filter(complete.cases(.)) %>%
  group_by(YearsCoding, YearsCodingProf) %>%
  summarise(count = n()) %>%
  ggplot(aes(YearsCoding, YearsCodingProf)) + 
    geom_tile(aes(fill = count), alpha = .7) + 
    scale_fill_distiller(name = 'Count', palette = 'Spectral') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  coord_equal() + 
  labs(x = 'Years Coding', y = 'Years Coding Professionally', title = 'Comparing total and professional coding years')
```  

This heatmap shows us the combinations of `YearsCoding` and `YearsCodingProf`. We could expect the majority of the values to be below the diagonal as total years coding should outweight those where it has been done professionally.   

We see a clear fade below the line where people may have spent a couple of years coding before going professional. 

The top value is 0-2 years professionally and 3-5 years overall, which would probably be that sweet zone where you are using Stack Overflow a lot in your job to troubleshoot issues that you might not have come across when you were coding as a hobby. 

***

## Monitor usage
`NumberMonitors` is a variable that seems to indicate how many monitors that the repsondent uses. This could be interresting to look at as it is something that I talk with colleagues about.  
Let's firstly just check what question was asked by looking at the `schema` data.  

```{r}
schema %>% filter(Column == 'NumberMonitors')
```  
*_How many monitors are set up at your workstation?_*  

It seems to be what we had imagined what a variable called `NumberMonitors` would contain.  

```{r}
glimpse(replies$NumberMonitors)
```  

We are working with a character column, although the choices are all numeric. `NA` values seem to be littered throughout as well, perhaps those that didn't answer all the questions deemed this one *"skippable"*.  

```{r "monitor_bar_graph", message=FALSE, error=FALSE, warning=FALSE }
monitors <- as_tibble(as.numeric(replies$NumberMonitors)) 
summary(monitors)
```  
We can see that the number of `NA` values increased, I will investigate those at a later date.  

```{r message=FALSE, error=FALSE, warning=FALSE}
ggplot(monitors, aes(value, fill = factor(..x..))) + 
  geom_bar() + 
  labs(x = 'Number of workstation monitors', y = 'Count', title = 'Number of workstation monitors') + 
  guides(fill = FALSE)
```
  
We seem to have a strong majority at 2 monitors. I wonder if this takes the form of the laptop screen and then one additional monitor?  

Of those respondents with 1 screen at that workstation, this might mean that they are working with desktop computers that already have a single large screen, so another isn't required.  

***

## Programming languages 
### Currently used languages 
Let's have a look at the programming languages that the respondents are currently using by having a look at the `LanguageWorkedWith` in the `replies` data. 

Let's see what format the data is kept in.
```{r}
head(unique(replies$LanguageWorkedWith), n = 5)
```  
So we have a character field where the languages that are being used are separated by a semi-colon. We need to find a way to separate those languages so that we are able to count them and produce a summary graph.  

`stringr` is a good place to start. 

```{r message=FALSE, error=FALSE, warning=FALSE}
current_languages <- unlist(str_split(replies$LanguageWorkedWith, ';'))
most_popular_languages <- as_tibble(table(current_languages)) %>% 
  arrange(desc(n)) 

head(most_popular_languages, n = 10)
```  
It looks like Javascript is the most currently used  languages. Let's plot them to get a better view of the lead.  

```{r message=FALSE, error=FALSE, warning=FALSE}
most_popular_languages %>% 
  top_n(15) %>%
  ggplot(aes(reorder(current_languages, n), n, fill = n)) + 
  geom_col() + 
  labs(x = 'Programming language', y = 'Count', title = 'Currently used programming languages') + 
  coord_flip() +
  scale_fill_continuous(name = 'Count')
```  
  
Looks like web developers could represent many of the respondents with JavaScript, HTML, CSS and SQL leading the way for currently used langauges. 

### Most desired programming languages
The survey also asked which languages developers wanted to use on future projects. This could be a good indication about future coding trends and tools that developers are going to use.  

Let's first have a look at the column to make sure that the format is the same as `LanguageWorkedWith`.

```{r}
head(replies$LanguageDesireNextYear, n = 4)
```

Yes that looks fine. We can reuse our code then to produce a similar plot as the one for `LanguageWorkedWith`.

```{r message=FALSE, error=FALSE, warning=FALSE}
future_languages <- unlist(str_split(replies$LanguageDesireNextYear, ';'))
most_desired_languages <- as_tibble(table(future_languages)) %>% 
  arrange(desc(n)) 

head(most_desired_languages, n = 10)
```  

Well it certainly looks like Javascript is here to stay! It tops the list of top languages currently worked with, and those that people desire to work with next year. Python is a climber as well, this might be suggestive of the growing data scene and the powers of python where that is concerned.  

PHP has dropped out of the top 10 list, showing developers apparent dislike of the language, but don't worry because it appears in the visualisation. 

```{r message=FALSE, error=FALSE, warning=FALSE}
most_desired_languages %>% 
  top_n(15) %>%
  ggplot(aes(reorder(future_languages, n), n, fill = n)) + 
  geom_col() + 
  labs(x = 'Programming language', y = 'Count', title = 'Most desired programming languages') + 
  coord_flip() +
  scale_fill_continuous(name = 'Count', high = '#f1f442', low = '#d60e0e')
``` 

### Language risers and fallers 
Let's see if we can investigate both the summaries that we have created at the same time to see if we can imply which languages are on the rise and which are falling away in their desirability. 

We can join the tables together using the language as the key in the two tables and by using the `left_join` function from `dplyr`.  

```{r}
joined_languages <- left_join(most_popular_languages, most_desired_languages, by = c('current_languages' = 'future_languages')) %>%
    rename(language = current_languages, currently_used = n.x, desired = n.y)
    
head(joined_languages, n = 10) # Top 10 rows of our newly joined data frame
```

The count sizes are drastically different between the two questions. Let's have a look and see whether one question was answered particularly more than the other.  

```{r}
replies %>%
    select(LanguageWorkedWith, LanguageDesireNextYear) %>%
    map_df(~ sum(is.na(.)))
```

It does seem that people were happier to say which languages they currently worked with compared to those that they might like to work with, or maybe they just haven't made their mind up yet.  

Another possible reason for this is that people didn't click the language from the first part (current languages) in the second part, indicating that they wanted to continue to use them in the future; this is stated in the question:  

``` {r}
filter(schema, Column == 'LanguageDesireNextYear') %>% '$'(QuestionText)
```

```{r}
joined_languages %>%
    top_n(10) %>%
    gather('status', 'count', -language) %>%
    ggplot(aes(reorder(language, count), count, fill = language)) + 
        geom_col() + 
        facet_grid(~ status) + 
        scale_fill_discrete(name = 'Language') + 
        labs(x = NULL, y = 'Count') + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))
```  

Just from looking at that, Go looks like it is set for a grow in popularity. The people that desire to use it is way above those that currently do.  
  
***

## AI opinions 
The survey included some questions about artificial intelligence that I think will be very interesting to have a look at and see what current developers feel about AI.  

```{r, 'find_ai_questions'}
ai_questions <- names(replies)[str_detect(names(replies), '^AI')]
print(ai_questions)

schema %>% filter(Column %in% ai_questions) # Filter to get the full question
```

We can see that there are 4 questions about AI. They cover:
- The danger of AI
- The exciting aspects of AI
- Who is responsibility of those working with advanced AI
- The future of AI

### Excitement 
*_What do you think is the most exciting aspect of increasingly advanced AI technology?_*
AI is a powerful tool that is pretty prominent in discussions and in the news at the moment, let's have a look and see what the respondents think are the most exciting aspects of AI. 

```{r}
replies %>% 
    filter(!is.na(AIInteresting)) %>%  
    group_by(AIInteresting) %>%
    summarise(count = n()) %>%
    ggplot(aes(reorder(AIInteresting, count), count, fill = factor(count) )) + 
        geom_col() + 
        geom_text(aes(label = AIInteresting, y = 500), size = 3, hjust = 0) +
        coord_flip() + 
        guides(fill = FALSE) + 
        labs(x = 'Answer', y = 'Count', title = 'Exciting aspects of AI') +
        theme(axis.text.y = element_blank()) + 
        scale_fill_brewer(palette = 'Oranges')
```

*Increasing automation of jobs* is the most common answer here from developers by a fairly large margin.  


### Danger 
*_What do you think is the most dangerous aspect of increasingly advanced AI technology?_*

```{r}
replies %>% 
    filter(!is.na(AIDangerous)) %>%  
    group_by(AIDangerous) %>%
    summarise(count = n()) %>%
    ggplot(aes(reorder(AIDangerous, count), count, fill = factor(count) )) + 
        geom_col() + 
        geom_text(aes(label = AIDangerous, y = 500), size = 3, hjust = 0) +
        coord_flip() + 
        guides(fill = FALSE) + 
        labs(x = 'Answer', y = 'Count', title = 'Dangers of AI') +
        theme(axis.text.y = element_blank()) + 
        scale_fill_brewer(palette = 'Reds')
```

*Algorithms making important decisions* is what concerns developers the most. Is this linked to how some people believe that AIs can be built and then left to function without human intervention to interpret the results? 


### Responsibility 
*_Whose responsibility is it, <u>primarily</u>, to consider the ramifications of increasingly advanced AI technology?_*

```{r}
replies %>% 
    filter(!is.na(AIResponsible)) %>%  
    group_by(AIResponsible) %>%
    summarise(count = n()) %>%
    ggplot(aes(reorder(AIResponsible, count), count, fill = factor(count) )) + 
        geom_col() + 
        geom_text(aes(label = AIResponsible, y = 500), size = 3, hjust = 0) +
        coord_flip() + 
        guides(fill = FALSE) + 
        labs(x = 'Answer', y = 'Count', title = 'Who is responsible for advanced AI') +
        theme(axis.text.y = element_blank()) + 
        scale_fill_brewer(palette = 'Greens')
```

With great power comes great responsibility. *The developers or the people creating the AI* are who is responsible as far as the developers are concerned; those who make the product must be in control of what they create. A government body is second which suggests that people believe that regulations should be in place surrounding the creation of AI technology. It would have been interesting to see the results had the developers been allowed to select more than one option for these questions, similar to the `DevType` question.    

### Future 
*_Overall, what's your take on the future of artificial intelligence?_*
   
```{r}
replies %>% 
    filter(!is.na(AIFuture)) %>%  
    group_by(AIFuture) %>%
    summarise(count = n()) %>%
    ggplot(aes(reorder(AIFuture, count), count, fill = factor(count) )) + 
        geom_col() + 
        geom_text(aes(label = AIFuture, y = 500), size = 3, hjust = 0) +
        coord_flip() + 
        guides(fill = FALSE) + 
        labs(x = 'Answer', y = 'Count', title = 'The future of AI') +
        theme(axis.text.y = element_blank()) + 
        scale_fill_brewer(palette = 'Blues')
```
Generally speaking, developers are more excited about the technology than worried about the dangers that might come with it.  
 
***
 
## Salary 
Let's explore those questions that contain salary information about our developer respondents.  

```{r message=FALSE, error=FALSE, warning=FALSE}
schema %>% filter(Column %in% schema$Column[str_detect(schema$Column, 'Salary')])
```

We can see that we have a salary input, as well as whether that sum is to do with a weekly, monthly or yearly wage. The useful column for us is going to be the `ConvertedSalary` which is the salary information gained from the survey but *converted to annual USD salaries using the exchange rate on 2018-01-18, assuming 12 working months and 50 working weeks*.  

I think this converted column is going to be easiest to use as the conversion will make the results directly comparable.  

```{r message=FALSE, error=FALSE, warning=FALSE}
converted_salaries <- replies %>% filter(!is.na(ConvertedSalary))

non_log <- ggplot(converted_salaries, aes(ConvertedSalary)) + 
    geom_histogram(bins = 50) +
    geom_freqpoly(alpha = .25, col = 'red') +
    labs(x = 'Salary (USD per annum)', y = 'Count', title = 'Distribution of annual salaries')
    
log <- ggplot(converted_salaries, aes(ConvertedSalary)) + 
    geom_histogram(bins = 50) +
    geom_freqpoly(alpha = .25, col = 'red') +
    scale_x_log10(breaks = c(1, 10, 100, 1000, 10000, 100000, 1000000), labels = c('1', '10', '100', '1,000', '10,000', '100,000', '1,000,000')) + 
    labs(x = 'Salary (USD per annum)', y = 'Count', title = 'Distribution of annual salaries - log scale')
    
grid.arrange(non_log, log)
```

There is a clear skew to the data, with lots of our salaries coming in below $250,000 per year, which definitely makes sense to me. If we put it in the log scale then we get a better view of the distribution of the converted salaries.  

### By gender

We can have a look at how the salary distributions between male and female respondents. There are lots of different gender options for this survey, but *Female* and *Male* have the most results so I will confine my analysis to those two. 

```{r message=FALSE, error=FALSE, warning=FALSE}
converted_salaries_gender <- converted_salaries %>% filter(!is.na(Gender), Gender %in% c('Male', 'Female'))

non_log_gender <- ggplot(converted_salaries_gender, aes(ConvertedSalary)) + 
    geom_histogram(bins = 50) +
    geom_freqpoly(alpha = .25, aes(col = Gender)) +
    labs(x = 'Salary (USD per annum)', y = 'Count', title = 'Distribution of annual salaries by gender') + 
    facet_wrap(~ Gender)
    
log_gender <- ggplot(converted_salaries_gender, aes(ConvertedSalary)) + 
    geom_histogram(bins = 50) +
    geom_freqpoly(alpha = .5, aes(col = Gender)) +
    labs(x = 'Salary (USD per annum)', y = 'Count', title = 'Distribution of annual salaries by gender - log scale') + 
    scale_x_log10(breaks = c(1, 10, 100, 1000, 10000, 100000, 1000000), labels = c('1', '10', '100', '1,000', '10,000', '100,000', '1,000,000')) + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    facet_wrap(~ Gender)
    
grid.arrange(non_log_gender, log_gender)
```

It looks as though we have a lot more information for *Male* than we do for *Female*. I think a boxplot might be more appropriate here to make more direct comparisons between the two groups.   

```{r message=FALSE, error=FALSE, warning=FALSE}
ggplot(converted_salaries_gender, aes(Gender, ConvertedSalary, fill = Gender)) + 
    geom_boxplot() + 
    labs(x = NULL, y = 'Salary (USD per annum)', title = 'Distribution of annual salaries by gender') +
    scale_y_log10(breaks = c(1, 10, 100, 1000, 10000, 100000, 1000000), labels = c('1', '10', '100', '1,000', '10,000', '100,000', '1,000,000')) +
    coord_flip()
```
   
***

# Initial conclusions
- This is a vast survey with many more explorations to be had
- There are lots of people who code for a hobby, but not as many are contributing to open source projects
- There are 183 countries represented by this survey, with United States being where most of the respondents are from
- Respondents tend to have coded for a couple of years prior to getting their first job
- The most common age group is 25-34 years
- 1 or 2 monitors at the workstation are the most common states, with some people clocking in at 4 screens  
- It seems that web developers could lead the way with Stack Overflow responses based on the top 4 used current programming languages
- JavaScript is popular now and is unlikely to fade as it topped the most desired programming language as well as the currently most used

## Upcoming sections  
- Developer lifestyle

***  
  
I would love to hear any **feedback or advice** that anyone has about what I have done here to start, and if you enjoyed please consider **upvoting** the kernel!  
Thanks for taking the time to have a look at my analysis. 
